{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9533203,"sourceType":"datasetVersion","datasetId":5806038}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -i https://test.pypi.org/simple/ krovetz","metadata":{"execution":{"iopub.status.busy":"2024-10-02T16:43:51.321725Z","iopub.execute_input":"2024-10-02T16:43:51.322214Z","iopub.status.idle":"2024-10-02T16:44:17.907250Z","shell.execute_reply.started":"2024-10-02T16:43:51.322169Z","shell.execute_reply":"2024-10-02T16:44:17.905961Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Looking in indexes: https://test.pypi.org/simple/\nCollecting krovetz\n  Downloading https://test-files.pythonhosted.org/packages/db/67/47724e97f563121bd14d946bea739d664979c8286c1b90b77b81e1e0e59e/krovetz-1.0.0.tar.gz (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: krovetz\n  Building wheel for krovetz (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for krovetz: filename=krovetz-1.0.0-cp310-cp310-linux_x86_64.whl size=289875 sha256=4ad5d47dec79b7771fafc286b1ab84010e3e8be7f987917bbbbe4c892cea31e8\n  Stored in directory: /root/.cache/pip/wheels/4b/8f/7b/ba27616be01a2d9b8281a280d25acc77f20ab605368f2d607d\nSuccessfully built krovetz\nInstalling collected packages: krovetz\nSuccessfully installed krovetz-1.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nimport re\nimport ast\nfrom nltk.stem import PorterStemmer\nimport warnings\nimport krovetz\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T16:45:12.297037Z","iopub.execute_input":"2024-10-02T16:45:12.297964Z","iopub.status.idle":"2024-10-02T16:45:12.309333Z","shell.execute_reply.started":"2024-10-02T16:45:12.297892Z","shell.execute_reply":"2024-10-02T16:45:12.308174Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"contraction_mapping = {\"ain't\": \"is not\", \"its\": \"it is\",\"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n\n                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n\n                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n\n                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n\n                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n\n                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n\n                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n\n                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n\n                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n\n                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n\n                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n\n                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n\n                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n\n                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n\n                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n\n                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n\n                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n\n                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n\n                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n\n                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n\n                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n\n                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n\n                           \"you're\": \"you are\", \"you've\": \"you have\"}","metadata":{"execution":{"iopub.status.busy":"2024-10-02T16:16:35.112221Z","iopub.execute_input":"2024-10-02T16:16:35.112976Z","iopub.status.idle":"2024-10-02T16:16:35.132671Z","shell.execute_reply.started":"2024-10-02T16:16:35.112897Z","shell.execute_reply":"2024-10-02T16:16:35.130144Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"stop_words = set(stopwords.words('english')) \ndef text_cleaner(text):\n    newString = text.lower()\n    newString = re.sub(r'\\([^)]*\\)', '', newString)\n    newString = re.sub('\"','', newString)\n    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n    newString = re.sub(r\"'s\\b\",\"\",newString)\n    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n    tokens = [w for w in newString.split() if not w in stop_words]\n    long_words=[]\n    for i in tokens:\n        if len(i)>=3:                  #removing short word\n            long_words.append(i)   \n    return (\" \".join(long_words)).strip()","metadata":{"execution":{"iopub.status.busy":"2024-10-02T16:16:35.135159Z","iopub.execute_input":"2024-10-02T16:16:35.135756Z","iopub.status.idle":"2024-10-02T16:16:35.155292Z","shell.execute_reply.started":"2024-10-02T16:16:35.135687Z","shell.execute_reply":"2024-10-02T16:16:35.153870Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"keywords_df=pd.read_csv(\"/kaggle/input/keywords-title/keywords_title.csv\")\nkeywords_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-02T16:44:25.665049Z","iopub.execute_input":"2024-10-02T16:44:25.666305Z","iopub.status.idle":"2024-10-02T16:44:25.778942Z","shell.execute_reply.started":"2024-10-02T16:44:25.666242Z","shell.execute_reply":"2024-10-02T16:44:25.777699Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 13228 entries, 0 to 13227\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Unnamed: 0  13228 non-null  int64 \n 1   Title       13228 non-null  object\n 2   Keywords    13228 non-null  object\ndtypes: int64(1), object(2)\nmemory usage: 310.2+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"keywords_df.drop(['Unnamed: 0'],axis=1,inplace=True)\nkeywords_df['Keywords'] = keywords_df['Keywords'].apply(ast.literal_eval)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T16:44:25.889685Z","iopub.execute_input":"2024-10-02T16:44:25.890159Z","iopub.status.idle":"2024-10-02T16:44:28.285118Z","shell.execute_reply.started":"2024-10-02T16:44:25.890112Z","shell.execute_reply":"2024-10-02T16:44:28.283943Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for i in range(13228):\n    words=keywords_df['Keywords'][i]\n    for j in range(len(words)):\n        words[j]=list(words[j])\n    keywords_df['Keywords'][i]=words\nprint(keywords_df['Keywords'][10])","metadata":{"execution":{"iopub.status.busy":"2024-10-02T16:44:28.287115Z","iopub.execute_input":"2024-10-02T16:44:28.287485Z","iopub.status.idle":"2024-10-02T16:44:32.166346Z","shell.execute_reply.started":"2024-10-02T16:44:28.287446Z","shell.execute_reply":"2024-10-02T16:44:32.165123Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[['naruto', 0.6194], ['konohagakure', 0.4758], ['kyuubi', 0.4646], ['ninja', 0.4147], ['hokage', 0.3895], ['demon', 0.3415], ['uzumaki', 0.3361], ['rampage', 0.3155], ['deadly', 0.2892], ['village', 0.2886], ['havoc', 0.2874], ['sacrificed', 0.2837], ['attacked', 0.2537], ['foes', 0.251], ['fox', 0.2509], ['fourth', 0.2478], ['oments', 0.2434], ['monstrous', 0.2417], ['life', 0.2346], ['leader', 0.2302], ['birth', 0.2268], ['nine', 0.2209], ['order', 0.211], ['hidden', 0.2103], ['living', 0.2074]]\n","output_type":"stream"}]},{"cell_type":"code","source":"ks = krovetz.PyKrovetzStemmer()\nfor i in range(13228):\n    words=keywords_df['Keywords'][i]\n    for j in range(len(words)):\n        words[j][0]=ks.stem(words[j][0])\n    keywords_df['Keywords'][i]=words\nprint(keywords_df['Keywords'][10])","metadata":{"execution":{"iopub.status.busy":"2024-10-02T16:45:16.248436Z","iopub.execute_input":"2024-10-02T16:45:16.249431Z","iopub.status.idle":"2024-10-02T16:45:20.557161Z","shell.execute_reply.started":"2024-10-02T16:45:16.249381Z","shell.execute_reply":"2024-10-02T16:45:20.556017Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"[['naruto', 0.6194], ['konohagakure', 0.4758], ['kyuubi', 0.4646], ['ninja', 0.4147], ['hokage', 0.3895], ['demon', 0.3415], ['uzumaki', 0.3361], ['rampage', 0.3155], ['deadly', 0.2892], ['village', 0.2886], ['havoc', 0.2874], ['sacrifice', 0.2837], ['attack', 0.2537], ['foe', 0.251], ['fox', 0.2509], ['fourth', 0.2478], ['oment', 0.2434], ['monstrous', 0.2417], ['life', 0.2346], ['leader', 0.2302], ['birth', 0.2268], ['nine', 0.2209], ['order', 0.211], ['hidden', 0.2103], ['living', 0.2074]]\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_text=\"ninja saves the village\"\nsample_text=text_cleaner(sample_text)\nresults={}\nfor i in sample_text.split():\n    for j in range(13228):\n        words=keywords_df['Keywords'][j]\n        for k in range(len(words)):\n            if(words[k][0]==i):\n                if words[k][0] in results.keys() or words[k][0] in results.values():\n                    results[keywords_df['Title'][j]]+=words[k][1]\n                else:\n                    results[keywords_df['Title'][j]]=words[k][1]","metadata":{"execution":{"iopub.status.busy":"2024-10-02T17:08:22.527374Z","iopub.execute_input":"2024-10-02T17:08:22.527909Z","iopub.status.idle":"2024-10-02T17:08:23.213782Z","shell.execute_reply.started":"2024-10-02T17:08:22.527864Z","shell.execute_reply":"2024-10-02T17:08:23.212753Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"sorted_results = dict(sorted(results.items(), key=lambda item: item[1], reverse=True))\nsorted_results=list(sorted_results.items())\nfor i in range(10):\n    print(sorted_results[i])","metadata":{"execution":{"iopub.status.busy":"2024-10-02T17:13:06.011388Z","iopub.execute_input":"2024-10-02T17:13:06.012156Z","iopub.status.idle":"2024-10-02T17:13:06.019105Z","shell.execute_reply.started":"2024-10-02T17:13:06.012106Z","shell.execute_reply":"2024-10-02T17:13:06.017989Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"('Ninjutsu Hinotama Kozou: Edo no Maki', 0.6682)\n('Ninja Hattori-kun (2012) Special', 0.6369)\n('Nintama Rantarou', 0.6275)\n('Ninja Slayer From Animation', 0.6231)\n('Ninja Bugei-chou', 0.5941)\n('Shuranosuke Zanmaken: Shikamamon no Otoko', 0.5908)\n('Jigen Sengokushi: Kuro no Shishi - Jinnai-hen', 0.5892)\n('Rekka no Honoo', 0.5874)\n('Ninja Collection', 0.5772)\n('Soccer', 0.5768)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}